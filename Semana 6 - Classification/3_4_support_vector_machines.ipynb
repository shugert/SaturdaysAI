{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "Corresponds with modu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data that is saved locally\n",
    "data = pd.read_csv(\"microfinance_tweets.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Sentiment'] == 'negative', 'Sentiment'] = -1\n",
    "data.loc[data['Sentiment'] == 'neutral', 'Sentiment'] = 0\n",
    "data.loc[data['Sentiment'] == 'positive', 'Sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Date</th>\n",
       "      <th>Favorites</th>\n",
       "      <th>User</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @atmadiprayET: Here's why Janalakshmi Finan...</td>\n",
       "      <td>3/22/2018 5:40</td>\n",
       "      <td>0</td>\n",
       "      <td>Saloni Shukla</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ecosmob: Ecosmob's #Mobility solutions for...</td>\n",
       "      <td>3/22/2018 5:36</td>\n",
       "      <td>0</td>\n",
       "      <td>Sindhav Bhageerath</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Project have big future! Microfinance is belie...</td>\n",
       "      <td>3/22/2018 5:27</td>\n",
       "      <td>0</td>\n",
       "      <td>Konstantin #savedroidICO</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Online #Banking-  Yako Microfinance Bank prov...</td>\n",
       "      <td>3/22/2018 5:21</td>\n",
       "      <td>0</td>\n",
       "      <td>YakoMicrofinance</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MICROFINANCE EVENT: 3rd BoP Global Network Sum...</td>\n",
       "      <td>3/22/2018 5:19</td>\n",
       "      <td>0</td>\n",
       "      <td>MicroCapital</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments            Date  \\\n",
       "0  RT @atmadiprayET: Here's why Janalakshmi Finan...  3/22/2018 5:40   \n",
       "1  RT @ecosmob: Ecosmob's #Mobility solutions for...  3/22/2018 5:36   \n",
       "2  Project have big future! Microfinance is belie...  3/22/2018 5:27   \n",
       "3  #Online #Banking-  Yako Microfinance Bank prov...  3/22/2018 5:21   \n",
       "4  MICROFINANCE EVENT: 3rd BoP Global Network Sum...  3/22/2018 5:19   \n",
       "\n",
       "   Favorites                      User  Polarity  Sentiment  \n",
       "0          0             Saloni Shukla -0.100000         -1  \n",
       "1          0        Sindhav Bhageerath -0.062500          0  \n",
       "2          0  Konstantin #savedroidICO  0.166667          1  \n",
       "3          0          YakoMicrofinance  0.500000          1  \n",
       "4          0              MicroCapital  0.045455          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_features = vectorizer.fit_transform(train['Comments'])\n",
    "test_features =  vectorizer.transform(test['Comments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have vectorized our data such that each index corresponds with a word as well as the frequency of that word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 585)\t2\n",
      "  (0, 778)\t1\n",
      "  (0, 788)\t1\n",
      "  (0, 1301)\t1\n",
      "  (0, 1302)\t1\n",
      "  (0, 1940)\t1\n",
      "  (0, 1994)\t1\n",
      "  (0, 2088)\t1\n",
      "  (0, 2230)\t1\n",
      "  (0, 3106)\t1\n",
      "  (0, 3381)\t2\n",
      "  (0, 3573)\t1\n",
      "  (0, 3770)\t2\n",
      "  (0, 4161)\t1\n",
      "  (0, 4516)\t1\n",
      "  (0, 5257)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many types of SVMs, but we will first try a linear SVM, the most basic. This means that the decision boundary will be linear. <br>\n",
    "\n",
    "There is another input called decision_function_shape. The two options of one versus rest, and one versus one. This relates to how the decision boundary separates points, whether it separates negative points from everyone else or negative points from neutral points, etc. (https://pythonprogramming.net/support-vector-machine-parameters-machine-learning-tutorial/). The default is one versus rest. One versus rest takes less computational power but may be thrown off by outliers and don't do well on imbalanced data sets, e.g. more of one class than another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')  \n",
    "clf.fit(train_features, train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = clf.predict(train_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 188   19    0]\n",
      " [   6 1540    0]\n",
      " [   0    0  839]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.97      0.91      0.94       207\n",
      "          0       0.99      1.00      0.99      1546\n",
      "          1       1.00      1.00      1.00       839\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2592\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(train['Sentiment'],y_train)) \n",
    "print(classification_report(train['Sentiment'],y_train))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 41   8   3]\n",
      " [  8 386   3]\n",
      " [  1   9 190]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.82      0.79      0.80        52\n",
      "          0       0.96      0.97      0.96       397\n",
      "          1       0.97      0.95      0.96       200\n",
      "\n",
      "avg / total       0.95      0.95      0.95       649\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test['Sentiment'],y_pred)) \n",
    "print(classification_report(test['Sentiment'],y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the performance of the SVM? We can also adjust gamma to account for overfitting, but it doesn't look like we've overfit too much given the training and test performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that support vectors are the data points that lie closest to the decision surface (or hyperplane). We can figure out what those data points are below for each class we are classifying, noting that we have three classes for negative, neutral, and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 531)\t1.0\n",
      "  (0, 1440)\t1.0\n",
      "  (0, 2371)\t1.0\n",
      "  (0, 2769)\t1.0\n",
      "  (0, 2775)\t2.0\n",
      "  (0, 2780)\t1.0\n",
      "  (0, 3106)\t1.0\n",
      "  (0, 3157)\t1.0\n",
      "  (0, 3312)\t1.0\n",
      "  (0, 3381)\t1.0\n",
      "  (0, 3496)\t1.0\n",
      "  (0, 3729)\t1.0\n",
      "  (0, 4796)\t1.0\n",
      "  (0, 4864)\t1.0\n",
      "  (0, 4964)\t1.0\n",
      "  (0, 5021)\t1.0\n",
      "  (0, 5059)\t1.0\n",
      "  (0, 5092)\t1.0\n",
      "  (0, 5156)\t2.0\n",
      "  (0, 5638)\t1.0\n",
      "  (1, 374)\t2.0\n",
      "  (1, 585)\t1.0\n",
      "  (1, 1885)\t1.0\n",
      "  (1, 2484)\t2.0\n",
      "  (1, 2485)\t1.0\n",
      "  :\t:\n",
      "  (1299, 3729)\t1.0\n",
      "  (1299, 3861)\t1.0\n",
      "  (1299, 3999)\t1.0\n",
      "  (1299, 4102)\t1.0\n",
      "  (1299, 5156)\t2.0\n",
      "  (1299, 5370)\t1.0\n",
      "  (1300, 614)\t1.0\n",
      "  (1300, 934)\t1.0\n",
      "  (1300, 1213)\t1.0\n",
      "  (1300, 1401)\t1.0\n",
      "  (1300, 1473)\t1.0\n",
      "  (1300, 1518)\t1.0\n",
      "  (1300, 1684)\t1.0\n",
      "  (1300, 1925)\t1.0\n",
      "  (1300, 2097)\t1.0\n",
      "  (1300, 2501)\t1.0\n",
      "  (1300, 3106)\t1.0\n",
      "  (1300, 3487)\t1.0\n",
      "  (1300, 4358)\t1.0\n",
      "  (1300, 4913)\t1.0\n",
      "  (1300, 5104)\t1.0\n",
      "  (1300, 5156)\t1.0\n",
      "  (1300, 5158)\t1.0\n",
      "  (1300, 5573)\t1.0\n",
      "  (1300, 5627)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for the number of points in each class using another function. Here we see that most support vectors are in our last class, the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([152, 713, 436])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the support vector in our original data using the indices provided for us with clf.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8,   21,   34, ..., 2573, 2585, 2587])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 531)\t1\n",
      "  (0, 1440)\t1\n",
      "  (0, 2371)\t1\n",
      "  (0, 2769)\t1\n",
      "  (0, 2775)\t2\n",
      "  (0, 2780)\t1\n",
      "  (0, 3106)\t1\n",
      "  (0, 3157)\t1\n",
      "  (0, 3312)\t1\n",
      "  (0, 3381)\t1\n",
      "  (0, 3496)\t1\n",
      "  (0, 3729)\t1\n",
      "  (0, 4796)\t1\n",
      "  (0, 4864)\t1\n",
      "  (0, 4964)\t1\n",
      "  (0, 5021)\t1\n",
      "  (0, 5059)\t1\n",
      "  (0, 5092)\t1\n",
      "  (0, 5156)\t2\n",
      "  (0, 5638)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_features[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check different kernel types, with rbf being gaussian and sigmoid being similar to the sigmoid function in logistic regression. A visualization is simplest to understand below:\n",
    "\n",
    "<img src=\"svm shapes.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf')  \n",
    "clf.fit(train_features, train['Sentiment'])\n",
    "\n",
    "y_pred = clf.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  52   0]\n",
      " [  0 397   0]\n",
      " [  0 200   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        52\n",
      "          0       0.61      1.00      0.76       397\n",
      "          1       0.00      0.00      0.00       200\n",
      "\n",
      "avg / total       0.37      0.61      0.46       649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lina\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test['Sentiment'],y_pred)) \n",
    "print(classification_report(test['Sentiment'],y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='sigmoid')  \n",
    "clf.fit(train_features, train['Sentiment'])\n",
    "\n",
    "y_pred = clf.predict(test_features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  52   0]\n",
      " [  0 397   0]\n",
      " [  0 200   0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        52\n",
      "          0       0.61      1.00      0.76       397\n",
      "          1       0.00      0.00      0.00       200\n",
      "\n",
      "avg / total       0.37      0.61      0.46       649\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lina\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test['Sentiment'],y_pred)) \n",
    "print(classification_report(test['Sentiment'],y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the linear SVM performs best on this model from both a precision and recall perspective. Remember that precision are the accuracy of the prediction and recall is how much of the true positive space we are capturing. \n",
    "\n",
    "What does this mean about our underlying data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/, https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html, https://gist.github.com/WittmannF/60680723ed8dd0cb993051a7448f7805"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
